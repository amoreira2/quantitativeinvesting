What is Quantitative Investing?
====================

Quantitative investing is about using
large and diverse data
sets through exploration, prediction, and inference together with theory to reach better investment decisions.  Exploration involves
identifying patterns in asset prices.  Prediction involves using information
we know to make informed guesses about values we wish we knew.  Inference
involves quantifying our degree of certainty: will the patterns that we found in our data also appear in new data? How accurate are our predictions? Our primary
tools for exploration are visualizations and descriptive statistics, for
prediction are regression analysis and machine learning, and for inference are
statistical tests and models.

Statistics is a central component of Quantitative investing because statistics
studies how to make robust conclusions based on incomplete information. Computing
is a central component because programming allows us to apply analysis
techniques to the large and diverse data sets that arise in real-world
applications: not just numbers, but also text, images, and videos.
For this we will mostly focus on numerical data, but the analysis here will extend naturally
to a variety of other inputs.

Quantitative investing is better described as the combination of traditional finance theory with data science.

TBD

Data are descriptions of the world around us, collected through observation and
stored on computers. Computers enable us to infer properties of the world from
these descriptions. Data science is the discipline of drawing conclusions from
data using computation. There are three core aspects of effective data
analysis: exploration, prediction, and inference. This text develops a
consistent approach to all three, introducing statistical ideas and fundamental
ideas in computer science concurrently. We focus on a minimal set of core
techniques that can be applied to a vast range of real-world
applications. A foundation in data science requires not only understanding
statistical and computational techniques, but also recognizing how they apply
to real scenarios.

For whatever aspect of the world we wish to study—whether it's the Earth's
weather, the world's markets, political polls, or the human mind—data we
collect typically offer an incomplete description of the subject at hand. A
central challenge of data science is to make reliable conclusions using this
partial information.

In this endeavor, we will combine two essential tools: computation and
randomization. For example, we may want to understand climate change trends
using temperature observations. Computers will allow us to use all available
information to draw conclusions. Rather than focusing only on the average
temperature of a region, we will consider the whole range of temperatures
together to construct a more nuanced analysis. Randomness will allow us to
consider the many different ways in which incomplete information might be
completed. Rather than assuming that temperatures vary in a particular way, we
will learn to use randomness as a way to imagine many possible scenarios that
are all consistent with the data we observe.

Applying this approach requires learning to program a computer, and so this
text interleaves a complete introduction to programming that assumes no prior
knowledge. Readers with programming experience will find that we cover several
topics in computation that do not appear in a typical introductory computer
science curriculum. Data science also requires careful reasoning about numerical
quantities, but this text does not assume any background in mathematics or
statistics beyond basic algebra. You will find very few equations in this text.
Instead, techniques are described to readers in the same language in which they
are described to the computers that execute them—a programming language.


Why Data Science?
=================

Most important decisions are made with only partial information and uncertain
outcomes. However, the degree of uncertainty for many decisions can be reduced
sharply by access to large data sets and the computational tools
required to analyze them effectively. Data-driven decision making has already
transformed a tremendous breadth of industries, including finance, advertising,
manufacturing, and real estate. At the same time, a wide range of academic
disciplines are evolving rapidly to incorporate large-scale data analysis into
their theory and practice.

Studying data science enables individuals to bring these techniques to bear on
their work, their scientific endeavors, and their personal decisions. Critical
thinking has long been a hallmark of a rigorous education, but critiques are
often most effective when supported by data. A critical analysis of any aspect
of the world, may it be business or social science, involves inductive
reasoning; conclusions can rarely been proven outright, but only supported by
the available evidence. Data science provides the means to make precise,
reliable, and quantitative arguments about any set of observations. With
unprecedented access to information and computing, critical thinking about
any aspect of the world that can be measured would be incomplete without
effective inferential techniques.

The world has too many unanswered questions and difficult challenges to leave
this critical reasoning to only a few specialists. All educated members of
society can build the capacity to reason about data. The tools, techniques,
and data sets are all readily available; this text aims to make them
accessible to everyone.
